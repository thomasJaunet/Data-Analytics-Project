{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "This notebook is meant to present some models to fit our dataset with the boroughs one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5296 entries, 0 to 5295\n",
      "Data columns (total 12 columns):\n",
      "Unnamed: 0                           5296 non-null int64\n",
      "price                                5296 non-null int64\n",
      "minimum_nights                       5296 non-null int64\n",
      "number_of_reviews                    5296 non-null int64\n",
      "reviews_per_month                    5296 non-null float64\n",
      "availability_365                     5296 non-null int64\n",
      "room_type_Entire home/apt            5296 non-null int64\n",
      "room_type_Private room               5296 non-null int64\n",
      "room_type_Shared room                5296 non-null int64\n",
      "neighbourhood_Harlem                 5296 non-null int64\n",
      "neighbourhood_Morningside Heights    5296 non-null int64\n",
      "neighbourhood_Upper West Side        5296 non-null int64\n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 496.6 KB\n"
     ]
    }
   ],
   "source": [
    "filename = 'listings_neibourhood.csv'\n",
    "data_borough = pd.read_csv(filename)\n",
    "data_borough.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_borough['price']\n",
    "del data_borough['Unnamed: 0']\n",
    "del data_borough['price']\n",
    "del data_borough['number_of_reviews']\n",
    "del data_borough['reviews_per_month']\n",
    "data_borough['availability_365'] = (data_borough['availability_365'] - data_borough['availability_365'].mean())/(data_borough['availability_365'].std())**2\n",
    "data_borough['minimum_nights'] = (data_borough['minimum_nights'] - data_borough['minimum_nights'].mean())/(data_borough['minimum_nights'].std())**2\n",
    "X = data_borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Mean Absolute Error: 58.4277\n",
      "Test Set Mean Absolute Error: 59.9533\n"
     ]
    }
   ],
   "source": [
    "#Fit regression model\n",
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=0.3,\n",
    "    loss='huber',\n",
    "    random_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "# Save the trained model to a file so we can use it in other programs\n",
    "#joblib.dump(model, 'trained_house_classifier_model_year_sq.pkl')\n",
    "\n",
    "# Find the error rate on the training set\n",
    "mse = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mse = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the grid search to ameliorate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'loss': 'huber', 'max_depth': 4, 'max_features': 1.0, 'min_samples_leaf': 3, 'n_estimators': 500}\n",
      "Training Set Mean Absolute Error: 57.9445\n",
      "Test Set Mean Absolute Error: 62.0376\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "# Parameters we want to try\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 2000],\n",
    "    'max_depth': [4, 6],\n",
    "    'min_samples_leaf': [3, 5, 9],\n",
    "    'learning_rate': [0.1, 0.05, 0.02],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber']\n",
    "}\n",
    "\n",
    "# Define the grid search we want to run. Run it with six cpus in parallel.\n",
    "gs_cv = GridSearchCV(model, param_grid, n_jobs=6)\n",
    "\n",
    "# Run the grid search - on only the training data!\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the parameters that gave us the best result!\n",
    "print(gs_cv.best_params_)\n",
    "\n",
    "# Find the error rate on the training set using the best parameters\n",
    "mse = mean_absolute_error(y_train, gs_cv.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set using the best parameters\n",
    "mse = mean_absolute_error(y_test, gs_cv.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the grid search, we see that we have a slightly better training estimation but a test set estimation a bit worst ( we overfit more than with the previous set of parameters). Our model is not very accurate. It is not surprising since we don't have enough explanatory variables. Basically, we have the average of Airbnb listings per neighborhood, which is a food first approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neighborhoods_near_Columbia.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model to a file so we can use it in other programs\n",
    "joblib.dump(model, 'Neighborhoods_near_Columbia.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
